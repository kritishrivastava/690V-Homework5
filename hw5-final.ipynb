{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 5 - VAST Challenge 2011 - Mini Challenge 1 \n",
    "\n",
    "Author: Suhas Keshavamurthy\n",
    "        \n",
    "        Kriti Shrivastava (Spire ID: 31041848)\n",
    "\n",
    "Datasource: http://hcil2.cs.umd.edu/newvarepository/VAST%20Challenge%202011/taskdescription-of-all2011challenges-printfromoriginalwebisteofchallenge.pdf\n",
    "\n",
    "#### Task Description: \n",
    "Pick a VAST Challenge. This is to be the VAST Challenge for the final project.  Identify what ML algorithms you will need to run on the data. These could be one algorithm you will run several times or different algorithms. Explain your selection.  Find one or more similar example data set(s) anywhere on the web (check the data web sites the syllabus suggested) and run the algorithms. Identify which one you think will work on the VAST Challenge you selected. What visualizations do you think you need?\n",
    "\n",
    "###### Bokeh Version used: 0.12.6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description:\n",
    "\n",
    "##### Mini Challenge 1  Characterization of an Epidemic Spread\n",
    "\n",
    "Vastopolis is a major metropolitan area with a population of approximately two million residents. During the last few\n",
    "days, health professionals at local hospitals have noticed a dramatic increase in reported illnesses. Observed\n",
    "symptoms are largely flu­like and include fever, chills,sweats, aches and pains, fatigue, coughing, breathing difficulty,\n",
    "nausea and vomiting, diarrhea, and enlarged lymph nodes. More recently, there have been several deaths believed\n",
    "to be associated with the current outbreak. City officials fear a possible epidemic and are mobilizing emergency\n",
    "management resources to mitigate the impact. You have been charged with providing an assessment of the\n",
    "situation.\n",
    "\n",
    "We provide you with two datasets. The first one contains microblog messages collected from various devices with\n",
    "GPS capabilities. These devices include laptop computers, handheld computers, and cellular phones. The second\n",
    "one contains map information for the entire metropolitan area. The map dataset contains a satellite image with\n",
    "labeled highways, hospitals, important landmarks, and water bodies. We also provide supplemental tables for\n",
    "population statistics and observed weather data. Additional information is provided in the README file.\n",
    "MC 1.1 Origin and Epidemic Spread: Identify approximately where the outbreak started on the map (ground zero\n",
    "location). If possible, outline the affected area. Explain how you arrived at your conclusion. (Short answer)\n",
    "MC 1.2 Epidemic Spread: Present a hypothesis on how the infection is being transmitted. For example, is the\n",
    "method of transmission person­to­person, airborne, waterborne, or something else? Identify the trends that support\n",
    "your hypothesis. Is the outbreak contained? Is it necessary for emergency management personnel to deploy\n",
    "treatment resources outside the affected area? Explain your reasoning. (Detailed answer)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ML Algorithms we plan to use and why\n",
    "\n",
    "The primary source of data for this problem is the 'Twitter dataset'. The tweets provide an indication of the disease, time and location. The dataset consists of a huge number of tweets during a given time period. \n",
    "The first step is to filter the tweets related to the disease. Here we can use NLP techniques to identify the appropriate tweets by analyzing the messages. \n",
    "\n",
    "The NLP process\n",
    "Step 1:\n",
    "Pre-processing the data. First step would be to remove stop words, remove whitespace and punctuation, lemmatization (convert to root word), and apply N-grams.\n",
    "\n",
    "Step 2:\n",
    "    Supervised Learning:\n",
    "    Next we will apply Word2Vec technique to convert the text to features. We can use either BOW (Continuous bag of words) or skip-gram model to do this. Before we are able to apply Word2Vec technique we need a training set. The simplest way to do this for this particular dataset is to parse the dataset messages for few common words that we can identify is relevant for our problem. These words can be 'flu', 'sick', 'well' (and other epidemic related key words specified in the problem statement). Now we can mark these text messages as relevant and use it as the training dataset. Now we can use the Word2Vec technique to identify all relevant messages that are related to the epidemic. Between BOW and skip-gram model, we need to see which provides better results although from an initial guess it appears that skip-gram is more relevant for our case.\n",
    "    Unsupervised Learning:\n",
    "    We can also attempt to apply unsupervised learning techniques like LDA (Latent Dirichlet allocation) to classify the messages into groups (topics). The challenge here would be to estimate number of topics (as the tweet data is going to be largely random). \n",
    "    \n",
    "Step 3: \n",
    "    Classification:\n",
    "    We can then use a classfication algorithm like Random Forest, SVM or Logistic Regression on the supervised learning outcome to identify relevant tweets. The accuracy needs to be calculated for each of these algorithms. If the accuracy is sufficiently high we can proceed with choosing the messages from the entire dataset.\n",
    "    It is a similar case with the unsupervised learning approach. If the estimated term frequency and overall term frequency are close to each other then we have a higher confidence that the classification generated by this model is accurate and we can use the terms with high correlation to extract relevant tweets.\n",
    "    \n",
    "Once the relevant tweets are identified we obtain the timestamp and location of the tweets. It is assumed that this location and time corresponds to the location and time of outbreak. While this is not necessarily true, over a large dataset it will help us identify the trends. \n",
    "One example of a false positive is \"Benjamin has the flu oh the suffering...\". Here the person posting the tweet may not have the flu and is referencing a third party. Her location of the tweet might also not be where Benjamin is not currently situated.\n",
    "One additional approach can be tracking the location of all people (using the ID field). If the number of people with flu (as identified above) and without flu are roughly proportionate or much less than the other, in a given area in a given time frame, then we can predict that the flu is not spreading from person to person.\n",
    "\n",
    "Now with this information we can perform groupby operation on day, time, location and ID on the reduced relevant dataset.\n",
    "\n",
    "This information in itself might be sufficient to perform certain analysis.\n",
    "We can group the location information (where the disease has occured) and identify areas in Vastopolis where the epidemic is rampant. We apply clustering ML algorithms here. But since we are interested in obtaining the clusters, we need to apply algorithms like DBScan, MeanShift to identify number of clusters. We can also attempt to apply hierarchical clustering algorithms which do not require 'cluster number' as input.\n",
    "\n",
    "Now we can use the additional information provided in the input dataset to identify if other correlations exist for the spread of epidemic. \n",
    "\n",
    "1) We can attempt to identify if there is a correlation between wind direction and spread of the epidemic. This might indicate possible transmission over air of the disease \n",
    "2) It might be relevant to identify the severity of the disease by comparing the density of population with the number of diseased cases. Might indicate correlation with person-to-person transmission.\n",
    "3) From the map of the city, we can visually try to identify if the river (water source) might be a possible cause of the spread of the epidemic. (by observing the disease reporting location over the time-series data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Identify which one you think will work on the VAST Challenge you selected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizations needed\n",
    "\n",
    "The following visualizations are expected to be useful for this particular challenge\n",
    "\n",
    "Plot the location of sick reported against the background of the image of the city. Since the sick reported varies over time, provide the following interactions to the user. We can tag the tweet with the location (displayed when user hovers over the location)\n",
    "    1) We can create a play button, which plots growth of disease incidence by time like a video.\n",
    "    2) User can select date, time to plot locations at a particular point of time. \n",
    "A line graph which shows the rate of growth/decline of the epidemic can be plotted alongside of it.\n",
    "\n",
    "Visualization can also animate wind speed and direction for a given day.\n",
    "The population density for day and night can also be indicated on the background image. (This however does not seem extremely relevant to the problem during the analysis)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
